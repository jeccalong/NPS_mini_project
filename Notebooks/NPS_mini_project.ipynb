{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "976ec8e4",
   "metadata": {},
   "source": [
    "Get started with required imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e193758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests, os, time, lxml\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef3b073",
   "metadata": {},
   "source": [
    "Load API key from .env and run a sanity check to confirm value is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55392cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"NPS_API_KEY\")\n",
    "\n",
    "print(API_KEY is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dcc451",
   "metadata": {},
   "source": [
    "I'm going to use the dataset to create a dataframe. The data we need is on the second sheet, so I need to specify. I'll also look at the first few rows to make sure this is what I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05840986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.ExcelFile(r\"../data/NPS-Mortality-Data-CY2007-to-CY2024-Released-August-2024.xlsx\")\n",
    "df = df.parse(sheet_name=\"CY2007-Present Q2\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7c3e7",
   "metadata": {},
   "source": [
    "Use .info() to get a look at the column names, datatypes, and counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c4d542",
   "metadata": {},
   "source": [
    "Print a list of the columns that may be easier to reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31872693",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2aa06",
   "metadata": {},
   "source": [
    "I'm going to look more closely at the \"Cause of death\" and \"Cause of Death Group \\n...\" columns to see if this data is redundant, or if I need to use both in my analysis.\n",
    "\n",
    "Check if all values in all rows and columns are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57a9aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[\"Cause of Death\"] == df[\"Cause of Death Group \\n(Used in the NPS Mortality Dashboard) \"]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365bba3e",
   "metadata": {},
   "source": [
    "Since the are not duplicates, I'm going to build a mask to count how many mismatches are in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52eaa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_mismatch = df[\"Cause of Death\"] != df[\"Cause of Death Group \\n(Used in the NPS Mortality Dashboard) \"]\n",
    "print(\"Total rows:\", len(df))\n",
    "print(mask_mismatch.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6210484a",
   "metadata": {},
   "source": [
    "I'm going to look at some of the mismatches to see what the differences are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed6cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[mask_mismatch, [\"Cause of Death\", \"Cause of Death Group \\n(Used in the NPS Mortality Dashboard) \"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba255583",
   "metadata": {},
   "source": [
    "It seems like I will be able to use the \"Cause of Death\" column and ignore the group column for now. I'm going to look more closely at the cause of death column now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f77cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Cause of Death\").size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb697e5e",
   "metadata": {},
   "source": [
    "There are some obvious duplicates in that list, so I'm going to normalize the causes to try to catch duplicates. First I'm going to see how many unique values there are now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabd055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cause of Death\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6940e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cause of Death\"] = df[\"Cause of Death\"].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d756f",
   "metadata": {},
   "source": [
    "I want to see how many unique values I have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd6393",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cause of Death\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27ba5b",
   "metadata": {},
   "source": [
    "I'm going to look at a list of the unique values just to see what I have since there aren't that many. I'll sort them in alphabetical order so it will be a little easer to see duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a65d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(df[\"Cause of Death\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70425703",
   "metadata": {},
   "source": [
    "Looking over the columns, I don't see any duplicates or names that should be changed right now. I'm going to change them back to have an uppercase character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da858c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cause of Death\"] = df[\"Cause of Death\"].str.title()\n",
    "print(df[\"Cause of Death\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8cccf1",
   "metadata": {},
   "source": [
    "Now that I know what column to use and I have eliminated case mismatches, I'm going to build a plot to just look at the causes of death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394cc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_counts = df[\"Cause of Death\"].value_counts()\n",
    "\n",
    "cause_counts.plot(\n",
    "    kind=\"pie\",\n",
    "    autopct=\"%1.1f%%\",\n",
    "    figsize=(8,8),\n",
    "    startangle=90\n",
    ")\n",
    "\n",
    "plt.ylabel(\"\")\n",
    "plt.title(\"Cause of Death\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01a927",
   "metadata": {},
   "source": [
    "There are lots of less frequent causes that confuse this plot. I'll do some adjustments to make it more meaningful/easy to read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332b1a8c",
   "metadata": {},
   "source": [
    "I want to show the major causes of death. This will calculate the percentage of deaths attributed to each cause, and also group causes accounting for <5% of deaths be combined into an \"other\" category to avoid cluttering the plot. The variables defined here will be used in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547bab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_counts = df[\"Cause of Death\"].value_counts(dropna=False)\n",
    "percentages  = cause_counts / cause_counts.sum() * 100\n",
    "\n",
    "major_causes = percentages[percentages >= 5].copy()\n",
    "other_total  = percentages[percentages < 5].sum()\n",
    "if other_total > 0:\n",
    "    major_causes.loc[\"Other\"] = other_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ec688d",
   "metadata": {},
   "source": [
    "I'm going to define my color palette to be used with this plot. I'm also going to set the colors up be the same for both medical cause deaths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fdc43b",
   "metadata": {},
   "source": [
    "The project’s color palette (hex codes and ordered list) was assisted by ChatGPT to ensure consistent formatting and to streamline selection and presentation.\n",
    "\n",
    "After generation, I manually verified each hex code and palette entry by comparing them against the reference palette published here:  \n",
    "<https://siegal.bio.nyu.edu/color-palette/>\n",
    "\n",
    "No discrepencies were found other than the omission of black, which was intentional to avoid readability issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5b58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "okabe_ito = [\n",
    "    \"#E69F00\",\n",
    "    \"#56B4E9\",\n",
    "    \"#009E73\",\n",
    "    \"#F0E442\",\n",
    "    \"#0072B2\",\n",
    "    \"#D55E00\",\n",
    "    \"#CC79A7\", \n",
    "]\n",
    "OTHER_GREY = \"#9e9e9e\"\n",
    "\n",
    "def color_for_label(lbl):\n",
    "    s = str(lbl).strip().lower()\n",
    "    if s == \"other\":\n",
    "        return OTHER_GREY\n",
    "\n",
    "    if \"medical\" in s:\n",
    "        return \"#E69F00\"  # orange\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55b334",
   "metadata": {},
   "source": [
    "Now that the colors are defined, I'll build a for loop to cycle through the unused options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f885f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "used = {c for c in [color_for_label(x) for x in major_causes.index] if c}\n",
    "remaining = [c for c in okabe_ito if c not in used]\n",
    "colors = []\n",
    "idx = 0\n",
    "for lbl in major_causes.index:\n",
    "    c = color_for_label(lbl)\n",
    "    if c is None:\n",
    "        c = remaining[idx % len(remaining)]\n",
    "        idx += 1\n",
    "    colors.append(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad0f1c",
   "metadata": {},
   "source": [
    "Now I'm going to create a pie chart that shows the major causes of death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f97315",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    major_causes.values,\n",
    "    labels=major_causes.index,\n",
    "    colors=colors,\n",
    "    autopct=\"%1.1f%%\",\n",
    "    wedgeprops={\"linewidth\": 1.0, \"edgecolor\": \"white\"},\n",
    "    startangle=90\n",
    ")\n",
    "for t in texts:\n",
    "    t.set_color(\"#111111\")\n",
    "    t.set_fontsize(11)\n",
    "\n",
    "for t in autotexts:\n",
    "    t.set_fontsize(11)\n",
    "    t.set_color(\"#111111\")\n",
    "  \n",
    "\n",
    "ax.set_title(\"Major Causes of Death in NPS Territories\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b53b8e",
   "metadata": {},
   "source": [
    "Drowning is the most frequent cause of death, so I'm going to look at that more closely to see if there are any common threads. I'm going to look at the number of drownings in each territory/park to see if there are any outliers. First, I'm going to normalize the park names to check for any case mismatches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0fb3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Park Name\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9cdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Park Name\"] = df[\"Park Name\"].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef01be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Park Name\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255fe511",
   "metadata": {},
   "source": [
    "There was no change to the number of unique strings, so it doesn't seem like there are mismatches in this column. I'm going to change back to original caps formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4f3bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Park Name\"] = df[\"Park Name\"].str.title()\n",
    "print(df[\"Park Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8ad12",
   "metadata": {},
   "source": [
    "I want to see if there are any null values in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b940af9",
   "metadata": {},
   "source": [
    "I know there are no missing values, so I'm going to quickly look at the drowning deaths per territory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeff4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter for drowning\n",
    "drowning_df = df[df[\"Cause of Death\"] == \"Drowning\"]\n",
    "\n",
    "#Count drowning deaths in parks\n",
    "drowning_counts = drowning_df[\"Park Name\"].value_counts()\n",
    "\n",
    "#Create bar graph with data\n",
    "plt.figure(figsize=(14,6))\n",
    "drowning_counts.plot(kind=\"bar\")\n",
    "\n",
    "plt.title(\"Drowning Deaths by National Park\")\n",
    "plt.xlabel(\"Park Name\")\n",
    "plt.ylabel(\"Number of Drowning Deaths\")\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8468b873",
   "metadata": {},
   "source": [
    "It looks like there are some outliers, but you can't really see more than that since there are so many entries. I'm going to create another, neater plot with the top 15 parks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234aba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_drowning = drowning_counts.head(15).sort_values()\n",
    "\n",
    "top_drowning.plot(kind=\"barh\")\n",
    "plt.title(\"Top 15 Parks by Drowning Deaths\")\n",
    "plt.xlabel(\"Drowning Deaths\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce26f9",
   "metadata": {},
   "source": [
    "I'm not working with the age range values right now, but I'm going to go ahead and look at those nulls since the rest of the dataset is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f31122",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"Age Range\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f3648",
   "metadata": {},
   "source": [
    "So, there's problems. Unintentional, nan, and not reported should all be unknown values. 0 - 14 and 0-14 seem like duplicates. I need to fix the ranges and make as many as possible numeric values. I'm going to start by combining the unknown values and counting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88d0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_age = {\"Not Reported\", \"Unintentional\", \"Unknown\", None, np.nan}\n",
    "\n",
    "df[\"age_range_clean\"] = df[\"Age Range\"].replace(list(unknown_age), \"Unknown\")\n",
    "\n",
    "print(df[\"age_range_clean\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b02b0c",
   "metadata": {},
   "source": [
    "Now I'm going to normalize the spacing to combine the duplicate age ranges. I'm going to normalize the dashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db40814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age_range_clean\"] = (\n",
    "    df[\"age_range_clean\"]\n",
    "    .str.replace(r\"\\s*-\\s*\", \"-\", regex=True)  # normalize dashes\n",
    "    .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c7d1d3",
   "metadata": {},
   "source": [
    "I'm going to double check that the values combined correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f414e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"age_range_clean\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c5eba2",
   "metadata": {},
   "source": [
    "I may have to revisit 65+, depending on what type of analysis I want to do, but for now I'm going to leave it as is and comvert the numeric ranges into min and max values, and calculate the midpoint. I'll use nan value for the max age in the 65+ column. Being numeric values instead of strings will prepare the data for any by age statistical analysis I may want to do later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac847e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = df[\"age_range_clean\"].str.extract(r\"(?P<min>\\d+)-(?P<max>\\d+)\")\n",
    "df[\"age_min\"] = ranges[\"min\"].astype(float)\n",
    "df[\"age_max\"] = ranges[\"max\"].astype(float)\n",
    "\n",
    "mask_plus = df[\"age_range_clean\"].str.endswith(\"+\", na=False)\n",
    "df.loc[mask_plus, \"age_min\"] = df.loc[mask_plus, \"age_range_clean\"].str[:-1].astype(float)\n",
    "df.loc[mask_plus, \"age_max\"] = np.nan \n",
    "\n",
    "df[\"age_mid\"] = (df[\"age_min\"] + df[\"age_max\"]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880cf607",
   "metadata": {},
   "source": [
    "Confirm that the columns have been added as numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc7582",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5efe75",
   "metadata": {},
   "source": [
    "One more sanity check -- I want to see the values and make sure that the min/max/mid ages are correct, and the NaN values are as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2405cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[[\"age_range_clean\",\"age_min\",\"age_max\",\"age_mid\"]].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3742a36e",
   "metadata": {},
   "source": [
    "I know that I want to use data from other NPS datasets along with this information. I also know that there are 3 major sources (NPS Mortality Dataset, IRMA API, and NPS Data API) and the park name is inconsistent across all 3. The API datasets both use a 4 letter code that is  consistent. I'm going to use one of the APIs to match the names of the parks in the mortality dataset to the appropriate park code so that I may query either database for info with the 4 letter code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294a04bf",
   "metadata": {},
   "source": [
    "BASE = \"https://developer.nps.gov/api/v1/parks\"\n",
    "params = {\"limit\": 50, \"start\": 0, \"api_key\": API_KEY}\n",
    "r = requests.get(BASE, params=params, timeout=30)\n",
    "print(r.status_code) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edb8ab8",
   "metadata": {},
   "source": [
    "Requesting list of keys for data returned so I can see how to filter for the park code and the full name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302c48c4",
   "metadata": {},
   "source": [
    "BASE = \"https://developer.nps.gov/api/v1/parks\"\n",
    "params = {\"limit\": 50, \"start\": 0, \"api_key\": API_KEY}\n",
    "r = requests.get(BASE, params=params, timeout=30)\n",
    "data = r.json()[\"data\"]\n",
    "if data:\n",
    "    print(list(data[0].keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825cf089",
   "metadata": {},
   "source": [
    "I want the \"fullName\" and \"parkCode\" for each row. I'm going to craft an API call to build this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f7caa",
   "metadata": {},
   "source": [
    "def fetch_all_parks(api_key: str, page_size: int = 50, pause: float = 0.2) -> pd.DataFrame:\n",
    "    base = \"https://developer.nps.gov/api/v1/parks\"\n",
    "    start = 0\n",
    "    rows = []\n",
    "\n",
    "#Create a loop that will continue until there is no data or the data returned is < the page size\n",
    "    while True:\n",
    "        params = {\"limit\": page_size, \"start\": start, \"api_key\": api_key}\n",
    "        resp = requests.get(base, params=params, timeout=30)\n",
    "        resp.raise_for_status()\n",
    "        #convert the response from JSON text to Python dictionary\n",
    "        payload = resp.json()\n",
    "\n",
    "        data = payload.get(\"data\", [])\n",
    "        if not data:\n",
    "            break\n",
    "        \n",
    "        #The default parks response has more info than I need, so I'm going to filter just for the name and park code\n",
    "        for item in data:\n",
    "            rows.append({\n",
    "                \"fullName\": item.get(\"fullName\"),\n",
    "                \"parkCode\": item.get(\"parkCode\")\n",
    "            })\n",
    "\n",
    "        if len(data) < page_size:\n",
    "            break\n",
    "\n",
    "        start += page_size\n",
    "        time.sleep(pause)\n",
    "\n",
    "    return pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "df_parks = fetch_all_parks(API_KEY, page_size=50)\n",
    "df_parks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f5ce13",
   "metadata": {},
   "source": [
    "Saving the data with park names and park codes to a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78632a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of parks:\", len(df_parks))\n",
    "df_parks.to_csv(\"nps_parks_fullName_parkCode.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2597699c",
   "metadata": {},
   "source": [
    "Now we'll examine the new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1dd68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad01661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parks.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef8103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parks[\"fullName\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8e8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parks[\"parkCode\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288f2d89",
   "metadata": {},
   "source": [
    "Now that I have the names and the park codes, I'm going to build a dictionary with the df_parks dataframe that I can use to add the parkCode to our existing dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_map = dict(zip(df_parks[\"fullName\"], df_parks[\"parkCode\"]))\n",
    "\n",
    "#Make a copy of the mortality dataframe so we aren't modifying original\n",
    "df_with_codes = df.copy()\n",
    "\n",
    "#Add columns for parkCode and Park Name\n",
    "df_with_codes[\"parkCode\"] = df_with_codes[\"Park Name\"].map(code_map)\n",
    "\n",
    "#Merge data from df_parks into new columns for exact matches\n",
    "name_map = dict(zip(df_parks[\"fullName\"], df_parks[\"fullName\"]))\n",
    "df_with_codes[\"fullName_official\"] = df_with_codes[\"Park Name\"].map(name_map)\n",
    "\n",
    "#Print info about what was merged, what is missing\n",
    "total = len(df_with_codes)\n",
    "matched = df_with_codes[\"parkCode\"].notna().sum()\n",
    "print(f\"Total rows: {total}\")\n",
    "print(f\"Matched rows: {matched}\")\n",
    "print(f\"Unmatched rows: {total - matched}\")\n",
    "\n",
    "unmatched_names = (\n",
    "    df_with_codes.loc[df_with_codes[\"parkCode\"].isna(), \"Park Name\"]\n",
    "    .dropna()\n",
    "    .drop_duplicates()\n",
    "    .sort_values()\n",
    ")\n",
    "\n",
    "print(\"\\nUnique unmatched park names:\")\n",
    "for nm in unmatched_names:\n",
    "    print(\"-\", nm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e73d0d",
   "metadata": {},
   "source": [
    "Since there aren't that many, I'm going to create a manual map to add the park codes using the NPS.gov site as a reference (https://www.nps.gov/articles/000/historic-listing-of-nps-park-codes.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78c207b",
   "metadata": {},
   "source": [
    "The `manual_crosswalk` table used in this notebook was generated with the assistance of ChatGPT to minimize copy/paste and encoding errors in character-specific strings (e.g., *Haleakalā*, *Hawaiʻi*, *Wrangell–St. Elias*, “&” vs “and”, etc.). This helped prevent merge failures when normalizing park names.\n",
    "\n",
    " After generation, I manually verified every entry by comparing each `fullName`/`parkCode` against the official NPS website for accuracy. Any mismatches were corrected in the crosswalk file before use in the analysis.\n",
    "\n",
    "The resulting file is saved as `parkname_manual_crosswalk.csv` and versioned in the repository. If an NPS unit is renamed or redesignated in the future, the crosswalk should be reviewed and updated accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee083a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_crosswalk = pd.DataFrame([\n",
    "    (\"Big South Fork National River And Recreation Area\", \"Big South Fork National River & Recreation Area\", \"biso\"),\n",
    "    (\"Canyon De Chelly National Monument\",                \"Canyon de Chelly National Monument\",            \"cach\"),\n",
    "    (\"Castillo De San Marcos National Monument\",          \"Castillo de San Marcos National Monument\",      \"casa\"),\n",
    "    (\"George Washington Birthplace\",                      \"George Washington Birthplace National Monument\",\"gewa\"),\n",
    "    (\"Haleakala National Park\",                           \"Haleakalā National Park\",                       \"hale\"),\n",
    "    (\"Hawaii Volcanoes National Park\",                    \"Hawaiʻi Volcanoes National Park\",               \"havo\"),\n",
    "    (\"Jean Lafitte National Historical Park & Preserve\",  \"Jean Lafitte National Historical Park and Preserve\",\"jela\"),\n",
    "    (\"Kaloko-Honokohau National Historical Park\",         \"Kaloko-Honokōhau National Historical Park\",     \"kaho\"),\n",
    "    (\"National Mall & Memorial Parks\",                    \"National Mall and Memorial Parks\",              \"nama\"),\n",
    "    (\"New River Gorge National River\",                    \"New River Gorge National Park and Preserve\",    \"neri\"),  # redesignated; code remains NERI\n",
    "    (\"Not Reported\",                                      \"Not Reported\",                                  None),\n",
    "    (\"President'S Park (White House)\",                    \"President's Park (White House)\",                \"whho\"),\n",
    "    (\"Presidio Of San Francisco\",                         \"Presidio of San Francisco\",                     \"prsf\"),\n",
    "    (\"Redwood National And State Parks\",                  \"Redwood National and State Parks\",              \"redw\"),\n",
    "    (\"Suitland\",                                          \"Suitland Parkway (under National Capital Parks–East)\", \"nace\"),  # official unit under NACE\n",
    "    (\"Wilson'S Creek National Battlefield\",               \"Wilson's Creek National Battlefield\",           \"wicr\"),\n",
    "    (\"Wrangell - St Elias National Park & Reserve\",       \"Wrangell–St. Elias National Park & Preserve\",   \"wrst\"),\n",
    "    (\"Yorktown Battlefield Part Of Colonial National Historical Park\", \"Yorktown Battlefield, Colonial National Historical Park\", \"colo\"),  # site rolls up under COLO\n",
    "], columns=[\"Park Name\", \"fullName_manual\", \"parkCode_manual\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1e02bb",
   "metadata": {},
   "source": [
    "I'll save the manual_croswalk as a .csv, then continue to use the mask to add codes, and then show anything remaining that is still missing a code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebd4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "manual_crosswalk.to_csv(\"parkname_manual_crosswalk.csv\", index=False)\n",
    "\n",
    "# Build lookups (unique index)\n",
    "code_lookup = manual_crosswalk.set_index(\"Park Name\")[\"parkCode_manual\"]\n",
    "name_lookup = manual_crosswalk.set_index(\"Park Name\")[\"fullName_manual\"]\n",
    "\n",
    "df_with_codes[\"parkCode\"] = df_with_codes[\"parkCode\"].fillna(\n",
    "    df_with_codes[\"Park Name\"].map(code_lookup)\n",
    ")\n",
    "\n",
    "# Now recompute the mask for *currently* missing codes\n",
    "mask_missing_code = df_with_codes[\"parkCode\"].isna() & df_with_codes[\"Park Name\"].notna()\n",
    "\n",
    "df_with_codes.loc[mask_missing_code].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9f17a",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d81938",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_count = df_with_codes[\"parkCode\"].isna().sum()\n",
    "print(na_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130b8e6",
   "metadata": {},
   "source": [
    "Looking at the rows that are missing, they are all for unreported park names. This is expected since there can be no park code match. I don't need to do anything with these rows because I'm looking specifically at drowning deaths so the won't be included in my dataset. They may need to be excluded for different types of analysis, though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f1995c",
   "metadata": {},
   "source": [
    "Now that I have the codes I'll need to get data from NPS API systems and I've cleaned the rows I will be focusing on, I'm going to save this dataframe as a new .csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_codes.to_csv(\"df_with_codes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9c2189",
   "metadata": {},
   "source": [
    "Sanity check -- let's look at our new dataframe and see if any more cleaning needs to be done before querying for visitation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa11f2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69e120e",
   "metadata": {},
   "source": [
    "I haven't really loked at the \"outcome\" column, so we'll look more closely there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6d63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Outcome\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd55d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Outcome\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa78e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd262e0f",
   "metadata": {},
   "source": [
    "This doesn't add anything to our dataset. It seems to be a case mismatch, and we already know that each row is a \"Fatal Injury\". I'm going to drop the entire column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3aac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes.drop(\"Outcome\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee4119a",
   "metadata": {},
   "source": [
    "To keep track of what columns we've cleaned, I'll use this list:\n",
    "\n",
    "CLEANED\n",
    "Park Name                                                                \n",
    "Cause of Death                                                           \n",
    "_Cause of Death Group \\n(Used in the NPS Mortality Dashboard)             \n",
    "Age Range                                                                \n",
    "age_range_clean                                                          \n",
    "age_min                                                                 \n",
    "age_max                                                                 \n",
    "age_mid                                                                 \n",
    "parkCode                                                                 \n",
    "fullName_official                                                        \n",
    "\n",
    "TO BE CLEANED\n",
    "Incident Date                                                    \n",
    "Intent                                                                  \n",
    "Sex                                                                      \n",
    "Activity                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc44433",
   "metadata": {},
   "source": [
    "I'll look at the Incident Date more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445691f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Incident Date\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a464c8",
   "metadata": {},
   "source": [
    "These are in correct datetime format and I know there are no missing values, so I'll move on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7a8c4c",
   "metadata": {},
   "source": [
    "To keep track of what columns we've cleaned, I'll use this list:\n",
    "\n",
    "CLEANED\n",
    "Park Name                                                                \n",
    "Cause of Death                                                           \n",
    "_Cause of Death Group \\n(Used in the NPS Mortality Dashboard)             \n",
    "Age Range                                                                \n",
    "age_range_clean                                                          \n",
    "age_min                                                                 \n",
    "age_max                                                                 \n",
    "age_mid                                                                 \n",
    "parkCode                                                                 \n",
    "fullName_official                                                        \n",
    "Incident Date \n",
    "\n",
    "TO BE CLEANED                                                 \n",
    "Intent                                                                  \n",
    "Sex                                                                      \n",
    "Activity                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88ca218",
   "metadata": {},
   "source": [
    "We'll look at the intent column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c55510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Intent\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cfb8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Intent\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c78907",
   "metadata": {},
   "source": [
    "I want to see if the \"Medical\" rows all correspond with the various medical causes of death. I'm going to normalize the Intent and Cause of Death columns and then compare to how many I would expect with the medical categories (3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Intent_norm\"] = df_with_codes[\"Intent\"].astype(str).str.strip().str.casefold()\n",
    "df_with_codes[\"Cause_norm\"]  = df_with_codes[\"Cause of Death\"].astype(str).str.strip().str.casefold()\n",
    "\n",
    "# 1) First, see what causes appear under Intent == \"Medical\"\n",
    "medical_causes_found = (\n",
    "    df_with_codes.loc[df_with_codes[\"Intent_norm\"] == \"medical\", \"Cause_norm\"]\n",
    "      .dropna()\n",
    "      .unique()\n",
    ")\n",
    "print(\"Causes seen for Intent == Medical:\", medical_causes_found)\n",
    "print(\"Count:\", len(medical_causes_found))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0705fe",
   "metadata": {},
   "source": [
    "This is what I expected. I'm just going to double check that the number of medical intent fields matches the sum of the three types of medical cause fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da12fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_causes = [\n",
    "    \"Medical - Not During Physical Activity\",\n",
    "    \"Medical - During Physical Activity\",\n",
    "    \"Medical - Unknown\"\n",
    "]\n",
    "\n",
    "df_with_codes[\"Cause of Death\"].value_counts().loc[medical_causes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4a6aa",
   "metadata": {},
   "source": [
    "There are 640 medical causes, and 640 medical intents, so I believe they corrospond correctly. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f956f8ad",
   "metadata": {},
   "source": [
    "To keep track of what columns we've cleaned, I'll use this list:\n",
    "\n",
    "CLEANED\n",
    "Park Name                                                                \n",
    "Cause of Death                                                           \n",
    "_Cause of Death Group \\n(Used in the NPS Mortality Dashboard)             \n",
    "Age Range                                                                \n",
    "age_range_clean                                                          \n",
    "age_min                                                                 \n",
    "age_max                                                                 \n",
    "age_mid                                                                 \n",
    "parkCode                                                                 \n",
    "fullName_official                                                        \n",
    "Incident Date \n",
    "Intent  \n",
    "\n",
    "TO BE CLEANED                                                 \n",
    "                                                             \n",
    "Sex                                                                      \n",
    "Activity                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c32f25",
   "metadata": {},
   "source": [
    "We'll look at the Sex column next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964308a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a729012",
   "metadata": {},
   "source": [
    "These are the values we would expect and there are no missing values. No additional work is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163f968a",
   "metadata": {},
   "source": [
    "To keep track of what columns we've cleaned, I'll use this list:\n",
    "\n",
    "CLEANED\n",
    "Park Name                                                                \n",
    "Cause of Death                                                           \n",
    "_Cause of Death Group \\n(Used in the NPS Mortality Dashboard)             \n",
    "Age Range                                                                \n",
    "age_range_clean                                                          \n",
    "age_min                                                                 \n",
    "age_max                                                                 \n",
    "age_mid                                                                 \n",
    "parkCode                                                                 \n",
    "fullName_official                                                        \n",
    "Incident Date \n",
    "Intent  \n",
    "Sex\n",
    "\n",
    "TO BE CLEANED                                                 \n",
    "                                                                    \n",
    "Activity                                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c2408",
   "metadata": {},
   "source": [
    "Now we'll look more closely at the Activity data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Activity\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d39110f",
   "metadata": {},
   "source": [
    "I'm going to look at the number of unique values, normalize, and compare just like I did with the Cause of Death column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50747fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Activity\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Activity\"] = df[\"Activity\"].str.strip().str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae22f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Activity\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9974750",
   "metadata": {},
   "source": [
    "Now I'll add the caps back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311ac240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Activity\"] = df_with_codes[\"Activity\"].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0a40ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Activity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Activity\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120c4750",
   "metadata": {},
   "source": [
    "I can combine \"Rock Scrambeling\" and \"Rock Scrambling\". I considered combining \"Not Reported\" and \"Undetermined, but chose not to at this time because they do convey different information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fc1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Activity\"] = df_with_codes[\"Activity\"].replace(\n",
    "    \"Rock Scrambeling\", \"Rock Scrambling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ba1cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"Activity\"].sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ab7436",
   "metadata": {},
   "source": [
    "That's the last \"To Be Cleaned\" column. I'm going to create a new csv with the cleaned columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_with_codes.to_csv(\"df_with_codes_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e58959",
   "metadata": {},
   "source": [
    "I'm going to use this API call to obtain the total number of visitations for both recreation and nonrecreation in the month the death occured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ef5474",
   "metadata": {},
   "source": [
    "IRMA is looking for case sensitive all caps in the parkCode field, so I'm going to change that before building the API. I do have missing values in this column, so I'm going to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d9bd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"parkCode\"] = (df_with_codes[\"parkCode\"].str.upper())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806331ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes[\"parkCode\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c23f6a2",
   "metadata": {},
   "source": [
    "I'm going to look at a single row and build an API call to get the information for a single, manual entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fdfa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_codes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71600d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://irmaservices.nps.gov/v3/rest/stats/visitation\"\n",
    "params = {\n",
    "    \"unitCodes\": \"GLCA\",\n",
    "    \"startMonth\": 1, \"startYear\": 2007,\n",
    "    \"endMonth\": 1,   \"endYear\": 2007,\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "\n",
    "r = requests.get(BASE, params=params, headers={\"Accept\": \"application/json\"}, timeout=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a24960a",
   "metadata": {},
   "source": [
    "Check for 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4410b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.status_code) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739e93c7",
   "metadata": {},
   "source": [
    "I want to see the data that was returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r.json()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a919ac1d",
   "metadata": {},
   "source": [
    "Now that I know how to build the API call, I want to determine the data I need. I want to get the monthly visitation statistics for each park in the mortality dataset, for the duration of the mortality dataset. I can then selectively pull from that dataset as needed for analyisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d984ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_col = \"Incident Date\"\n",
    "code_col = \"parkCode\"\n",
    "\n",
    "df_with_visits = df_with_codes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59db4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the new dataframe to store this data\n",
    "df_with_visits = df_with_visits.dropna(subset=[\"parkCode\"])\n",
    "\n",
    "#Define the chronologically first and last index in the dataset\n",
    "i_first = df_with_visits[date_col].idxmin()\n",
    "i_last = df_with_visits[date_col].idxmax()\n",
    "\n",
    "first_row = df_with_visits.loc[i_first, [date_col, code_col]]\n",
    "last_row  = df_with_visits.loc[i_last,  [date_col, code_col]]\n",
    "\n",
    "print(\"First death:\", first_row.to_dict())\n",
    "print(\"Last death:\",  last_row.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ad6bd4",
   "metadata": {},
   "source": [
    "Sanity check -- make sure the missing parkCode values were dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435eefd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits[\"Incident Date\"].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81efd83f",
   "metadata": {},
   "source": [
    "Now that I know the first and last month to collect and have verified the API, I'm going to build an API call that collects the monthly visitation stats for every month 01/2007-06/2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30560c5e",
   "metadata": {},
   "source": [
    "BASE = \"https://irmaservices.nps.gov/v3/rest/stats/visitation\"\n",
    "params = {\n",
    "    \"unitCodes\": \"GLCA\",\n",
    "    \"startMonth\": 1, \"startYear\": 2007,\n",
    "    \"endMonth\": 6,   \"endYear\": 2024,\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "\n",
    "r = requests.get(BASE, params=params, headers={\"Accept\": \"application/json\"}, timeout=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43966a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = r.json()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e0972",
   "metadata": {},
   "source": [
    "I've got the call to collect the data for an individual park, but I want to collect all the parks in my dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed349b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://irmaservices.nps.gov/v3/rest/stats/visitation\"\n",
    "\n",
    "# 1) get unique park\n",
    "all_codes = (\n",
    "    df_with_visits[\"parkCode\"]\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.upper()\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i+n]\n",
    "\n",
    "CODES_PER_CALL = 50\n",
    "\n",
    "all_results = []\n",
    "\n",
    "with requests.Session() as s:\n",
    "    for chunk in chunk_list(all_codes, CODES_PER_CALL):\n",
    "        params = {\n",
    "            \"unitCodes\": \",\".join(chunk),\n",
    "            \"startMonth\": 1,\n",
    "            \"startYear\": 2007,\n",
    "            \"endMonth\": 6,\n",
    "            \"endYear\": 2024,\n",
    "            \"format\": \"json\",\n",
    "        }\n",
    "        r = s.get(BASE, params=params, headers={\"Accept\": \"application/json\"}, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        all_results.extend(data)\n",
    "\n",
    "visits_df = pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de08046d",
   "metadata": {},
   "source": [
    "I want to view the first few rows of the new visits dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ee17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7bbdb",
   "metadata": {},
   "source": [
    "I'm going to save this visitation information to a .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92343ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.to_csv(\"NPS_visitation_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503022e",
   "metadata": {},
   "source": [
    "Next, I'll check to see if there are any missing values in any of the fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c454ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d9309",
   "metadata": {},
   "source": [
    "Nothing is missing, so I'm going to check for completeness. If I received all the data I request, the number of rows for each UnitCode will be the same for each park."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe263d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the number of rows for each park code\n",
    "counts = visits_df[\"UnitCode\"].value_counts()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d6de20",
   "metadata": {},
   "source": [
    "There are 5 unique counts for unit codes, so I want to know why I don't have the same for the outliers. I'm going to define the one that is most common to be the expected, and then look for the other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbe5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the most common row using mode\n",
    "expected = counts.mode()[0]\n",
    "\n",
    "#show anything that doesn't match\n",
    "mismatch = counts[counts != expected]\n",
    "\n",
    "#Show the result\n",
    "mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ba469e",
   "metadata": {},
   "source": [
    "I'm going to make sure it wasn't a problem with my call to the api and make another call requesting all the data for just those park units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582211b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://irmaservices.nps.gov/v3/rest/stats/visitation\"\n",
    "\n",
    "list_missing_codes = [\"MISS\", \"SACR\", \"PAGR\", \"FRST\"]\n",
    "mismatch_codes = (pd.Series(list_missing_codes)\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.upper()\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i+n]\n",
    "\n",
    "CODES_PER_CALL = 50\n",
    "\n",
    "mismatch_all_results = []\n",
    "\n",
    "with requests.Session() as s:\n",
    "    for chunk in chunk_list(mismatch_codes, CODES_PER_CALL):\n",
    "        params = {\n",
    "            \"unitCodes\": \",\".join(chunk),\n",
    "            \"startMonth\": 1,\n",
    "            \"startYear\": 2007,\n",
    "            \"endMonth\": 6,\n",
    "            \"endYear\": 2024,\n",
    "            \"format\": \"json\",\n",
    "        }\n",
    "        r = s.get(BASE, params=params, headers={\"Accept\": \"application/json\"}, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        mismatch_all_results.extend(data)\n",
    "\n",
    "new_mismatch_data = pd.DataFrame(mismatch_all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e0912",
   "metadata": {},
   "source": [
    "Now that I have the data, I'm going to count the rows for each code like I did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4f6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_counts = new_mismatch_data[\"UnitCode\"].value_counts()\n",
    "mismatch_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1cac1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frst_rows = new_mismatch_data[new_mismatch_data[\"UnitCode\"] == \"FRST\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008bea3",
   "metadata": {},
   "source": [
    "I want to look at some of the rows to see what we do have. FRST is the park unit with the least rows, so I'll start there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "frst_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21fe8db",
   "metadata": {},
   "source": [
    "I want to confirm that there really is no data prior to the first month I have, which is 01/2023. I'm going to make one additional API call to see what the earliest record is just to confirm this isn't due to an error in my previous API call to get this info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5299bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://irmaservices.nps.gov/v3/rest/stats/visitation\"\n",
    "params = {\n",
    "    \"unitCodes\": \"FRST\",\n",
    "    \"startYear\": 2010,\n",
    "    \"endYear\": 2025,\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "r = requests.get(BASE, params=params)\n",
    "data = r.json()\n",
    "\n",
    "# find earliest record\n",
    "earliest = min([f\"{d['Year']}-{d['Month']:02}\" for d in data])\n",
    "earliest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ac9fe",
   "metadata": {},
   "source": [
    "I've confirmed that this is the earliest data available and I've done a google search to see if there is anything I can find that would explain why the data isn't available. I haven't found anything. \n",
    "\n",
    "I'm going to add the visitation data into my cleaned df with codes, so I'm just going to look at the first few rows to refresh my memory on my column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486d6fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964303ae",
   "metadata": {},
   "source": [
    "I see a few things that I can go ahead and clean up before I add the new data. I'm going to get rid of the original Intent and Cause fields and replace them with the normalized data. I'll get rid of the old Age Range Data and rename the cleaned data. I still have them in my orignal dataset if I need to reference the original version, and they're redundant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac64981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits = df_with_visits.drop(columns=[\"Age Range\", \"Intent\", \"Cause of Death\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8126687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0712dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f5677b",
   "metadata": {},
   "source": [
    "I'm going to pull the month and year out of my Incident Date datetime field so that I can use those as a key to match my visitation data and see if I'm missing data for any of the incidents in my mortality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e28d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits[\"Month\"] = df_with_visits[\"Incident Date\"].dt.month\n",
    "df_with_visits[\"Year\"]  = df_with_visits[\"Incident Date\"].dt.year\n",
    "df_with_visits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0486e93",
   "metadata": {},
   "source": [
    "Now I'm going to merge the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac291c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits = df_with_visits.merge(\n",
    "    visits_df,\n",
    "    how=\"left\",\n",
    "    left_on=[\"parkCode\", \"Month\", \"Year\"],\n",
    "    right_on=[\"UnitCode\", \"Month\", \"Year\"]\n",
    ")\n",
    "df_with_visits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b0641d",
   "metadata": {},
   "source": [
    "I want to check and see if any of the new columns have missing values. This will tell me if the data that is missing includes any of the incident dates for the mortality dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79219068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits[[\"NonRecreationVisitors\", \"RecreationVisitors\"]].isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3047855a",
   "metadata": {},
   "source": [
    "There's quite a bit of missing data, so I need to figure out why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_visits = df_with_visits[\n",
    "    df_with_visits[\"NonRecreationVisitors\"].isna() |\n",
    "    df_with_visits[\"RecreationVisitors\"].isna()\n",
    "]\n",
    "missing_visits.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc485d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_visits[\"parkCode\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e495efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_visits[\"parkCode\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcec968",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_visits[\"Park Name\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffe2cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_codes = missing_visits[\"parkCode\"].unique()\n",
    "missing_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes_in_visits = visits_df[\"UnitCode\"].unique()\n",
    "codes_with_data = [code for code in missing_codes if code in codes_in_visits]\n",
    "\n",
    "codes_with_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7caca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44fd8a8",
   "metadata": {},
   "source": [
    "I'm going to see if I made any errors in my manual crosswalk that could be causing this issue with the park codes. I'm going to create a dataframe with that .csv and see if any of the problematic codes are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b95bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk = pd.read_csv(\"parkname_manual_crosswalk.csv\")\n",
    "crosswalk.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67586c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "crosswalk[\"parkCode_manual\"] = crosswalk[\"parkCode_manual\"].str.upper()\n",
    "crosswalk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89077c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = crosswalk[crosswalk[\"parkCode_manual\"].isin(mismatch_counts.index)]\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f22f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "morematches = crosswalk[crosswalk[\"parkCode_manual\"].isin(missing_codes)]\n",
    "morematches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aef4af",
   "metadata": {},
   "source": [
    "I found a table that has all the historic codes for sites that may help me find the missing data. I'm going to try to directly download that table of information into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738803b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.nps.gov/articles/000/historic-listing-of-nps-park-codes.htm\"\n",
    "tables = pd.read_html(url)\n",
    "print(len(tables))          # how many tables pandas found\n",
    "df_codes = tables[0]        # pick the first one\n",
    "df_codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228a6023",
   "metadata": {},
   "source": [
    "It looks like I got the correct data, but the column names should actually be the data in row 0. I'm going to drop that row and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes.columns = df_codes.iloc[0]\n",
    "df_codes = df_codes.drop(df_codes.index[0])\n",
    "df_codes = df_codes.reset_index(drop=True)\n",
    "df_codes.columns = df_codes.columns.str.strip()\n",
    "df_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3831bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_codes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bad4fc",
   "metadata": {},
   "source": [
    "I'm going to combine my missing_coes and mismatch_counts but one is an array so I'll turn them both into lists first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_codes_list = list(missing_codes)\n",
    "mismatch_counts_list = list(mismatch_counts.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cad050",
   "metadata": {},
   "source": [
    "And then combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7afe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_missing = missing_codes_list + mismatch_counts_list\n",
    "combined_missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab03a11",
   "metadata": {},
   "source": [
    "There are duplicates so I'm going to delete them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092a6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_missing = list(set(combined_missing))\n",
    "combined_missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767cac83",
   "metadata": {},
   "source": [
    "I'm still not really sure why these codes are missing data. I'm going to do an API call for one of them to see if there is ANY visitation data available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f941ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://irmaservices.nps.gov/v3/rest/stats/visitation\"\n",
    "params = {\n",
    "    \"unitCodes\": \"SACR\",\n",
    "    \"startYear\": 2010,\n",
    "    \"endYear\": 2025,\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "r = requests.get(BASE, params=params)\n",
    "print(r.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b0ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://irmaservices.nps.gov/v3/rest/stats/visitation\"\n",
    "params = {\n",
    "    \"unitCodes\": \"SACR\",\n",
    "    \"startYear\": 2010,\n",
    "    \"endYear\": 2025,\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "r = requests.get(BASE, params=params)\n",
    "data = r.json()\n",
    "\n",
    "# find earliest record\n",
    "earliest = min([f\"{d['Year']}-{d['Month']:02}\" for d in data])\n",
    "earliest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4aaf88",
   "metadata": {},
   "source": [
    "I've been looking at the data on the NPS website and it seems like the codes used in the visitation stats don't match all the official codes. For example, Kings Canyon National Park shows a code of KICA, which isn't anywhere in my historical table or the official park codes table. To make matches, I'm going to download all the names and codes from the park so that I can find more matches for the parks units.\n",
    "\n",
    "On the NPS searchable page, I can find a drop down menu with all of the parks and park codes as they are listed in the visitation stats. I cannot find a complete listing and the park code is required to call the API so I can't get it from there. Using the inspect tool, I've found the code for the dropdown list that populates with all the park names and codes. It is pretty lengthy, so I'm going to copy it from the inpsect panel and save it in a new .html file called visit_codes.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13865267",
   "metadata": {},
   "source": [
    "I'm going to read that .html file in my notbook, and look the length and the first 500 characters to make sure it's opening correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8858881",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"visit_codes.html\", \"r\", encoding=\"utf-8\") as f:\n",
    "    html = f.read()\n",
    "\n",
    "print(len(html))\n",
    "print(html[:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2450f8",
   "metadata": {},
   "source": [
    "Now I'm going to use BeautifulSoup to find all the items in the boundlist that I copied. This should be all my parks. I'm going to look at the length to see if it's working correctly. Each item that has a class=\"x-boundlist-item\" should be an individual park, so I'm going to divide those into a list and see how many there are. I'm expcting just a little over 400, because that's how many national park units I know exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "items = soup.find_all(\"li\", class_=\"x-boundlist-item\")\n",
    "print(len(items))\n",
    "print(items[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1b894",
   "metadata": {},
   "source": [
    "Now that it's divided into each list item instead of a giant string of code, I'm going to put it into rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcfd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create blank place to hold the rows when they're created\n",
    "rows = []\n",
    "\n",
    "#create for loop that will go through all of the boundlist items \n",
    "for li in items:\n",
    "    #get just the text that would display withough the rest of the code\n",
    "    text = li.get_text(strip=True)   \n",
    "\n",
    "    #I'm going to use a regular expression to seperate the part in parentheses from the rest\n",
    "    m = re.match(r\"^(.*)\\(([^)]+)\\)$\", text)\n",
    "    if m:\n",
    "        name = m.group(1).strip()\n",
    "        code = m.group(2).strip()\n",
    "        rows.append({\"UnitName\": name, \"UnitCode\": code})\n",
    "    else:\n",
    "        # in case some weird row doesn't match that pattern\n",
    "        rows.append({\"UnitName\": text, \"UnitCode\": None})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_visit_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceb63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit_codes = pd.DataFrame(rows)\n",
    "\n",
    "df_visit_codes.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9492cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit_codes.tail(\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf064712",
   "metadata": {},
   "source": [
    "Since my loop indicated that rows missing park codes or in a different format should record visitsParkCode as \"None\", I'm going to count how many rows have None in that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a87f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_visit_codes[\"UnitCode\"] == \"None\").sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90692c",
   "metadata": {},
   "source": [
    "Now that I have this complete listing for the visitor statistics API, I'm going to save it to a new .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca871714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visit_codes.to_csv(\"../data/visit_codes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5df557",
   "metadata": {},
   "source": [
    "I'll use the API to call for all the parks available in the list and obtain all available visitor data, which I will then map to my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c871d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"https://irmaservices.nps.gov/v3/rest/stats/visitation\"\n",
    "\n",
    "all_codes = (\n",
    "    df_visit_codes[\"UnitCode\"]\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .str.upper()\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i+n]\n",
    "\n",
    "CODES_PER_CALL = 50\n",
    "\n",
    "all_results = []\n",
    "\n",
    "with requests.Session() as s:\n",
    "    for chunk in chunk_list(all_codes, CODES_PER_CALL):\n",
    "        params = {\n",
    "            \"unitCodes\": \",\".join(chunk),\n",
    "            \"startMonth\": 1,\n",
    "            \"startYear\": 2007,\n",
    "            \"endMonth\": 6,\n",
    "            \"endYear\": 2024,\n",
    "            \"format\": \"json\",\n",
    "        }\n",
    "        r = s.get(BASE, params=params, headers={\"Accept\": \"application/json\"}, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        all_results.extend(data)\n",
    "\n",
    "all_visits_df = pd.DataFrame(all_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37b784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visits_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7307d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5806dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268be6cb",
   "metadata": {},
   "source": [
    "The columns are the same. If my new data includes everything in my old data, I should have the same number of duplicate rows as I do rows in visits_df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62109360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on all columns to find exact duplicates between dataframes\n",
    "shared = all_visits_df.merge(visits_df, how=\"inner\")\n",
    "\n",
    "len(shared)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c61c392",
   "metadata": {},
   "source": [
    "Since that was what expected, I am going to overwrite the NPS_visitation_data.csv to hold all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fe72d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visits_df.to_csv(\"../data/NPS_visitation_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee4467",
   "metadata": {},
   "source": [
    "I'm going to add my new visitation unit codes to my mortality dataset so that I can put all the new data in the correct places.\n",
    "\n",
    "To efficiently determine the best matches for each park, I utilized ChatGPT. I uploaded df_with_visits.csv, as well as visit_codes.csv, and provide my list of parks without matches. I prompted ChatGPT to use information about NPS park structures, historical locations and unit codes, and geographic locations to determin the best match for incidents that didn't have data. That file is uploaded in the data folder as corrected_park_codes.csv. I'm going to use this code to help match my new visitation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edd44a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrected_park_codes = pd.read_csv(\"../Data/corrected_park_codes.csv\")\n",
    "\n",
    "df_corrected_park_codes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbcab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrected_park_codes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536fed8",
   "metadata": {},
   "source": [
    "I'm going to change some of the column names that ChatGPT generated to make it easier to utilize this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d82f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrected_park_codes = df_corrected_park_codes.rename(\n",
    "    columns={\"Queried parkCode\": \"parkCode\",\n",
    "             \"Matched visitsParkName\": \"UnitName\",\n",
    "             \"Matched visitsParkCode\": \"UnitCode\"})\n",
    "\n",
    "df_corrected_park_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd74d1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d487eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corrected_park_codes.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d796904a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits[\"UnitCode\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5ff1d3",
   "metadata": {},
   "source": [
    "Now I'm going to merge this info to df_with_visits df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554927d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) make sure there are no sneaky spaces in the corrected df\n",
    "#df_corrected_park_codes.columns = df_corrected_park_codes.columns.str.strip()\n",
    "\n",
    "# 1) now do the merge (this should work now)\n",
    "df_with_visits = df_with_visits.merge(\n",
    "    df_corrected_park_codes[[\"Park Name\", \"UnitCode\", \"UnitName\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"fullName_official\",\n",
    "    right_on=\"Park Name\",\n",
    "    suffixes=(\"\", \"_corr\")   # new cols from corrected df will be UnitCode_corr, UnitName_corr\n",
    ")\n",
    "\n",
    "# 2) fill ONLY where original was NaN, using the corrected ones\n",
    "df_with_visits[\"UnitCode\"] = df_with_visits[\"UnitCode\"].fillna(df_with_visits[\"UnitCode_corr\"])\n",
    "df_with_visits[\"UnitName\"] = df_with_visits[\"UnitName\"].fillna(df_with_visits[\"UnitName_corr\"])\n",
    "\n",
    "# 3) drop helper columns\n",
    "df_with_visits = df_with_visits.drop(columns=[\"UnitCode_corr\", \"UnitName_corr\", \"Park Name_corr\"])\n",
    "\n",
    "df_with_visits.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a723b81",
   "metadata": {},
   "source": [
    "Now I'll rerun my count to confirm codes were added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba311738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits[\"UnitCode\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be7f536",
   "metadata": {},
   "source": [
    "The number decreased so some were added, but I'm still missing rows. I want to look at the unique values and see which parks still aren't complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cb6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits[df_with_visits[\"UnitCode\"].isnull()][\"parkCode\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb7d4cb",
   "metadata": {},
   "source": [
    "Now I'm going to check if any of those parkCodes have any rows with a UnitCode, which would indicate that some data was downloade in the prior API call, but not all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f63271",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the parkCodes where UnitCode is null\n",
    "missing_codes = df_with_visits.loc[df_with_visits[\"UnitCode\"].isnull(), \"parkCode\"].unique()\n",
    "\n",
    "#Filter rows where parkCode is one of those, and UnitCode is NOT null\n",
    "partial_matches = df_with_visits.loc[\n",
    "    df_with_visits[\"parkCode\"].isin(missing_codes) & df_with_visits[\"UnitCode\"].notnull(),\n",
    "    [\"parkCode\", \"UnitCode\"]\n",
    "]\n",
    "\n",
    "#View the unique parkCodes that have both missing and present UnitCodes\n",
    "partial_matches[\"parkCode\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f846f",
   "metadata": {},
   "source": [
    "I still have some without matches. I again utilized ChatGPT to make matches in a new file, gpt_code_matches.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ab336",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more_corrected_park_codes = pd.read_csv(\"../Data/gpt_code_matches.csv\")\n",
    "\n",
    "df_more_corrected_park_codes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_more_corrected_park_codes = df_more_corrected_park_codes.rename(\n",
    "    columns={\"Queried parkCode\": \"parkCode\",\n",
    "             \"Matched visitsParkName\": \"UnitName\",\n",
    "             \"Matched visitsParkCode\": \"UnitCode\"})\n",
    "\n",
    "df_more_corrected_park_codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8477491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in extra matches from gpt_code_matches, using parkCode as the key\n",
    "df_with_visits = df_with_visits.merge(\n",
    "    df_more_corrected_park_codes[[\"parkCode\", \"UnitCode\", \"UnitName\"]],\n",
    "    how=\"left\",\n",
    "    on=\"parkCode\",\n",
    "    suffixes=(\"\", \"_gpt\")\n",
    ")\n",
    "\n",
    "# fill only missing values\n",
    "df_with_visits[\"UnitCode\"] = df_with_visits[\"UnitCode\"].fillna(df_with_visits[\"UnitCode_gpt\"])\n",
    "df_with_visits[\"UnitName\"] = df_with_visits[\"UnitName\"].fillna(df_with_visits[\"UnitName_gpt\"])\n",
    "\n",
    "# drop helper cols\n",
    "df_with_visits = df_with_visits.drop(columns=[\"UnitCode_gpt\", \"UnitName_gpt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1750,
   "id": "26be61a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>parkName</th>\n",
       "      <th>causeGroup</th>\n",
       "      <th>sex</th>\n",
       "      <th>activity</th>\n",
       "      <th>ageRange</th>\n",
       "      <th>ageMin</th>\n",
       "      <th>ageMax</th>\n",
       "      <th>ageMid</th>\n",
       "      <th>parkCode</th>\n",
       "      <th>officialName</th>\n",
       "      <th>intent</th>\n",
       "      <th>cause</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>Glen Canyon National Recreation Area</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Reported</td>\n",
       "      <td>65+</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GLCA</td>\n",
       "      <td>Glen Canyon National Recreation Area</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>899.0</td>\n",
       "      <td>29707.0</td>\n",
       "      <td>GLCA</td>\n",
       "      <td>Glen Canyon NRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-22</td>\n",
       "      <td>Golden Gate National Recreation Area</td>\n",
       "      <td>Drowning</td>\n",
       "      <td>Male</td>\n",
       "      <td>Vessel Related</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOGA</td>\n",
       "      <td>Golden Gate National Recreation Area</td>\n",
       "      <td>unintentional</td>\n",
       "      <td>drowning</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>992940.0</td>\n",
       "      <td>GOGA</td>\n",
       "      <td>Golden Gate NRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-22</td>\n",
       "      <td>Golden Gate National Recreation Area</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Male</td>\n",
       "      <td>Vessel Related</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOGA</td>\n",
       "      <td>Golden Gate National Recreation Area</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>undetermined</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>992940.0</td>\n",
       "      <td>GOGA</td>\n",
       "      <td>Golden Gate NRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-29</td>\n",
       "      <td>Natchez Trace Parkway</td>\n",
       "      <td>Motor Vehicle Crash</td>\n",
       "      <td>Female</td>\n",
       "      <td>Driving</td>\n",
       "      <td>15-24</td>\n",
       "      <td>15.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>NATR</td>\n",
       "      <td>Natchez Trace Parkway</td>\n",
       "      <td>unintentional</td>\n",
       "      <td>motor vehicle crash</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>577583.0</td>\n",
       "      <td>486268.0</td>\n",
       "      <td>NATR</td>\n",
       "      <td>Natchez Trace PKWY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-29</td>\n",
       "      <td>Natchez Trace Parkway</td>\n",
       "      <td>Motor Vehicle Crash</td>\n",
       "      <td>Female</td>\n",
       "      <td>Driving</td>\n",
       "      <td>45-54</td>\n",
       "      <td>45.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>NATR</td>\n",
       "      <td>Natchez Trace Parkway</td>\n",
       "      <td>unintentional</td>\n",
       "      <td>motor vehicle crash</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>577583.0</td>\n",
       "      <td>486268.0</td>\n",
       "      <td>NATR</td>\n",
       "      <td>Natchez Trace PKWY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                              parkName           causeGroup  \\\n",
       "0 2007-01-01  Glen Canyon National Recreation Area         Undetermined   \n",
       "1 2007-01-22  Golden Gate National Recreation Area             Drowning   \n",
       "2 2007-01-22  Golden Gate National Recreation Area         Undetermined   \n",
       "3 2007-01-29                 Natchez Trace Parkway  Motor Vehicle Crash   \n",
       "4 2007-01-29                 Natchez Trace Parkway  Motor Vehicle Crash   \n",
       "\n",
       "      sex        activity ageRange  ageMin  ageMax  ageMid parkCode  \\\n",
       "0    Male    Not Reported      65+    65.0     NaN     NaN     GLCA   \n",
       "1    Male  Vessel Related  Unknown     NaN     NaN     NaN     GOGA   \n",
       "2    Male  Vessel Related  Unknown     NaN     NaN     NaN     GOGA   \n",
       "3  Female         Driving    15-24    15.0    24.0    19.5     NATR   \n",
       "4  Female         Driving    45-54    45.0    54.0    49.5     NATR   \n",
       "\n",
       "                           officialName         intent                cause  \\\n",
       "0  Glen Canyon National Recreation Area   undetermined         undetermined   \n",
       "1  Golden Gate National Recreation Area  unintentional             drowning   \n",
       "2  Golden Gate National Recreation Area   undetermined         undetermined   \n",
       "3                 Natchez Trace Parkway  unintentional  motor vehicle crash   \n",
       "4                 Natchez Trace Parkway  unintentional  motor vehicle crash   \n",
       "\n",
       "   Month  Year  NonRecreationVisitors  RecreationVisitors UnitCode  \\\n",
       "0      1  2007                  899.0             29707.0     GLCA   \n",
       "1      1  2007                    0.0            992940.0     GOGA   \n",
       "2      1  2007                    0.0            992940.0     GOGA   \n",
       "3      1  2007               577583.0            486268.0     NATR   \n",
       "4      1  2007               577583.0            486268.0     NATR   \n",
       "\n",
       "             UnitName  \n",
       "0     Glen Canyon NRA  \n",
       "1     Golden Gate NRA  \n",
       "2     Golden Gate NRA  \n",
       "3  Natchez Trace PKWY  \n",
       "4  Natchez Trace PKWY  "
      ]
     },
     "execution_count": 1750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_visits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "id": "3b91a0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(11)"
      ]
     },
     "execution_count": 1752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_visits[\"UnitCode\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1748,
   "id": "7a3d1819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['APPA', 'AMME'], dtype=object)"
      ]
     },
     "execution_count": 1748,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_visits[df_with_visits[\"UnitCode\"].isnull()][\"parkCode\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ec55af",
   "metadata": {},
   "source": [
    "This is what I'm expecting to see. NPS data is not available for either the Appalachian Trail or the American Memorial Park in Saipan.\n",
    "\n",
    "Now I'm going to do some housecleaning on my mortality dataset so that I can appropriately merge the visitation data. I'll start by looking at the header to make sure I'm working in the correct place with the correct fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fef5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ace19",
   "metadata": {},
   "source": [
    "First I'm going to clean up the column names to be clear, concise, and consistent. I'll start by looking at the list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea83860",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits = df_with_visits.rename(\n",
    "    columns={\"Incident Date\": \"date\",\n",
    "             \"Park Name\": \"parkName\",\n",
    "             \"Cause of Death Group \\n(Used in the NPS Mortality Dashboard) \":\"causeGroup\", \n",
    "             \"Sex\": \"sex\",\n",
    "             \"Activity\": \"activity\",\n",
    "             \"age_range_clean\": \"ageRange\", \n",
    "             \"age_min\": \"ageMin\", \n",
    "             \"age_max\": \"ageMax\",\n",
    "             \"age_mid\": \"ageMid\",\n",
    "             \"fullName_official\": \"officialName\",\n",
    "              \"Intent_norm\": \"intent\", \n",
    "              \"Cause_norm\": \"cause\"}\n",
    ")\n",
    "\n",
    "df_with_visits.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de1e3e3",
   "metadata": {},
   "source": [
    "Now we'll merge the visitation data to the fields that now have parkCodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff33f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visits_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in extra matches from gpt_code_matches, using parkCode as the key\n",
    "df_with_visits = df_with_visits.merge(\n",
    "    all_visits_df[[\"UnitCode\", \"Month\", \"Year\", \"NonRecreationVisitors\", \"RecreationVisitors\"]],\n",
    "    how=\"left\",\n",
    "    on=[\"UnitCode\", \"Month\", \"Year\"],\n",
    "    suffixes=(\"\", \"_visit\")\n",
    ")\n",
    "\n",
    "# fill only where you were missing values\n",
    "df_with_visits[\"NonRecreationVisitors\"] = df_with_visits[\"NonRecreationVisitors\"].fillna(df_with_visits[\"NonRecreationVisitors_visit\"])\n",
    "df_with_visits[\"RecreationVisitors\"] = df_with_visits[\"RecreationVisitors\"].fillna(df_with_visits[\"RecreationVisitors_visit\"])\n",
    "\n",
    "# drop helper cols\n",
    "df_with_visits = df_with_visits.drop(columns=[\"NonRecreationVisitors_visit\", \"RecreationVisitors_visit\"])\n",
    "\n",
    "df_with_visits.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660319c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdce2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_visits.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1768,
   "id": "dd4596d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BAWA', 'APPA', 'SACR', 'PAGR', 'FRST', 'AMME'], dtype=object)"
      ]
     },
     "execution_count": 1768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_visits.loc[df_with_visits[\"RecreationVisitors\"].isna(), \"parkCode\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc0e0bc",
   "metadata": {},
   "source": [
    "We should only be missing all of the data for the parks we previously identified, Appalachian Trail and American Memorial Park. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1770,
   "id": "a69d84ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>officialName</th>\n",
       "      <th>parkCode</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2763</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4214</th>\n",
       "      <td>American Memorial Park</td>\n",
       "      <td>AMME</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4421</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4422</th>\n",
       "      <td>Appalachian National Scenic Trail</td>\n",
       "      <td>APPA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           officialName parkCode UnitCode  RecreationVisitors\n",
       "563   Appalachian National Scenic Trail     APPA      NaN                 NaN\n",
       "1470  Appalachian National Scenic Trail     APPA      NaN                 NaN\n",
       "2619  Appalachian National Scenic Trail     APPA      NaN                 NaN\n",
       "2704  Appalachian National Scenic Trail     APPA      NaN                 NaN\n",
       "2763  Appalachian National Scenic Trail     APPA      NaN                 NaN\n",
       "2825  Appalachian National Scenic Trail     APPA      NaN                 NaN\n",
       "3154  Appalachian National Scenic Trail     APPA      NaN                 NaN\n",
       "3222  Appalachian National Scenic Trail     APPA      NaN                 NaN\n",
       "4214             American Memorial Park     AMME      NaN                 NaN\n",
       "4421  Appalachian National Scenic Trail     APPA      NaN                 NaN\n",
       "4422  Appalachian National Scenic Trail     APPA      NaN                 NaN"
      ]
     },
     "execution_count": 1770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_visits.loc[\n",
    "    df_with_visits[\"RecreationVisitors\"].isna() & df_with_visits[\"UnitCode\"].isna(),\n",
    "    [\"officialName\", \"parkCode\", \"UnitCode\", \"RecreationVisitors\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1769,
   "id": "57fa597c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>NACA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     UnitCode  RecreationVisitors\n",
       "138      NACA                 NaN\n",
       "142      NACA                 NaN\n",
       "181      NACA                 NaN\n",
       "186      NACA                 NaN\n",
       "296      NACA                 NaN\n",
       "...       ...                 ...\n",
       "4530     NACA                 NaN\n",
       "4551     NACA                 NaN\n",
       "4565     NACA                 NaN\n",
       "4599     NACA                 NaN\n",
       "4628     NACA                 NaN\n",
       "\n",
       "[83 rows x 2 columns]"
      ]
     },
     "execution_count": 1769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_visits.loc[df_with_visits[\"parkCode\"] == \"BAWA\", [\"UnitCode\", \"RecreationVisitors\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ca30b",
   "metadata": {},
   "source": [
    "I did research on NPS websites to determine if there may be any reasons for missing data for the remaining parks, BAWA, SACR, PAGR, FRST, that have some but not all of the data. My findings are:\n",
    "\n",
    "BAWA is a parkway and has gone many retoolings in how visitation data is collected. Sometimes the data is even collected by the FHWA in conjuction with NPS. I wan't able to find any alternative sources for the missing data. We will have to deal with these on a case by case basis to determine how lack of data may affect normalization.\n",
    "\n",
    "SACR - This is an island site that is run in conjunction with Canada. It is a part of the Acadia region, and the data may be stored under that park (ACAD). I'll see what I have from ACAD in my full visitation data file.\n",
    "\n",
    "PAGR was established in 2011, so there should not be data before then, and the earlier years may be incomplete/inaccurate. I will double check the earliest missing dates to confirm this is the only problem.\n",
    "\n",
    "FRST - Park began as National Monument on 25Mar2013 and became National Historic Park in 2014. Data should begin in 2013/2014. Will confirm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1771,
   "id": "1b346a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4960</td>\n",
       "      <td>ABLI</td>\n",
       "      <td>Abraham Lincoln Birthplace NHP</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5877</td>\n",
       "      <td>ABLI</td>\n",
       "      <td>Abraham Lincoln Birthplace NHP</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9868</td>\n",
       "      <td>ABLI</td>\n",
       "      <td>Abraham Lincoln Birthplace NHP</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17900</td>\n",
       "      <td>ABLI</td>\n",
       "      <td>Abraham Lincoln Birthplace NHP</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>21277</td>\n",
       "      <td>ABLI</td>\n",
       "      <td>Abraham Lincoln Birthplace NHP</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  NonRecreationVisitors  RecreationVisitors UnitCode  \\\n",
       "0      1                      0                4960     ABLI   \n",
       "1      2                      0                5877     ABLI   \n",
       "2      3                      0                9868     ABLI   \n",
       "3      4                      0               17900     ABLI   \n",
       "4      5                      0               21277     ABLI   \n",
       "\n",
       "                         UnitName  Year  \n",
       "0  Abraham Lincoln Birthplace NHP  2007  \n",
       "1  Abraham Lincoln Birthplace NHP  2007  \n",
       "2  Abraham Lincoln Birthplace NHP  2007  \n",
       "3  Abraham Lincoln Birthplace NHP  2007  \n",
       "4  Abraham Lincoln Birthplace NHP  2007  "
      ]
     },
     "execution_count": 1771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_visits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b891ed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_visits_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1776,
   "id": "24c37aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First and last per park ===\n",
      "  UnitCode  EarliestYear  EarliestMonth EarliestDate  EarliestVisitors  \\\n",
      "0     FRST          2023              1   2023-01-01                 0   \n",
      "1     PAGR          2016              1   2016-01-01               248   \n",
      "2     SACR          2013              1   2013-01-01                 0   \n",
      "\n",
      "   LatestYear  LatestMonth LatestDate  LatestVisitors  \n",
      "0        2024            6 2024-06-01           28962  \n",
      "1        2024            6 2024-06-01           31823  \n",
      "2        2024            6 2024-06-01            1854  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 1776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_rows = [\"NACA\", \"SACR\", \"PAGR\", \"FRST\"]\n",
    "\n",
    "# filter just those\n",
    "subset = all_visits_df[all_visits_df[\"UnitCode\"].isin(missing_rows)].copy()\n",
    "\n",
    "subset[\"Date\"] = pd.to_datetime(\n",
    "    subset[\"Year\"].astype(str) + \"-\" + subset[\"Month\"].astype(str) + \"-01\"\n",
    ")\n",
    "\n",
    "# 2) get earliest and latest row per park\n",
    "first_rows = subset.loc[\n",
    "    subset.groupby(\"UnitCode\")[\"Date\"].idxmin(),\n",
    "    [\"UnitCode\", \"Year\", \"Month\", \"Date\", \"RecreationVisitors\"]\n",
    "].rename(columns={\n",
    "    \"Year\": \"EarliestYear\",\n",
    "    \"Month\": \"EarliestMonth\",\n",
    "    \"Date\": \"EarliestDate\",\n",
    "    \"RecreationVisitors\": \"EarliestVisitors\"\n",
    "})\n",
    "\n",
    "last_rows = subset.loc[\n",
    "    subset.groupby(\"UnitCode\")[\"Date\"].idxmax(),\n",
    "    [\"UnitCode\", \"Year\", \"Month\", \"Date\", \"RecreationVisitors\"]\n",
    "].rename(columns={\n",
    "    \"Year\": \"LatestYear\",\n",
    "    \"Month\": \"LatestMonth\",\n",
    "    \"Date\": \"LatestDate\",\n",
    "    \"RecreationVisitors\": \"LatestVisitors\"\n",
    "})\n",
    "\n",
    "first_last = first_rows.merge(last_rows, on=\"UnitCode\")\n",
    "print(\"=== First and last per park ===\")\n",
    "print(first_last)\n",
    "\n",
    "\n",
    "gap_records = []\n",
    "\n",
    "for code, group in subset.groupby(\"UnitCode\"):\n",
    "    group = group.sort_values(\"Date\")\n",
    "    # full monthly range from first to last\n",
    "    full_range = pd.date_range(group[\"Date\"].min(), group[\"Date\"].max(), freq=\"MS\")\n",
    "    # which dates are actually present\n",
    "    present_dates = set(group[\"Date\"])\n",
    "    # find missing ones\n",
    "    missing = [d for d in full_range if d not in present_dates]\n",
    "    if missing:\n",
    "        gap_records.append({\n",
    "            \"UnitCode\": code,\n",
    "            \"MissingDates\": missing\n",
    "        })\n",
    "\n",
    "gaps_df = pd.DataFrame(gap_records)\n",
    "gaps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1773,
   "id": "c4aee97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Month, NonRecreationVisitors, RecreationVisitors, UnitCode, UnitName, Year]\n",
       "Index: []"
      ]
     },
     "execution_count": 1773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_visits_df.loc[all_visits_df[\"UnitCode\"] == \"NACA\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1774,
   "id": "b602f9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>parkName</th>\n",
       "      <th>causeGroup</th>\n",
       "      <th>sex</th>\n",
       "      <th>activity</th>\n",
       "      <th>ageRange</th>\n",
       "      <th>ageMin</th>\n",
       "      <th>ageMax</th>\n",
       "      <th>ageMid</th>\n",
       "      <th>parkCode</th>\n",
       "      <th>officialName</th>\n",
       "      <th>intent</th>\n",
       "      <th>cause</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>UnitName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2007-12-08</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>Motor Vehicle Crash</td>\n",
       "      <td>Not Reported</td>\n",
       "      <td>Driving</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAWA</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>unintentional</td>\n",
       "      <td>motor vehicle crash</td>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NACA</td>\n",
       "      <td>National Capital Parks Combined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2007-12-29</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>Motor Vehicle Crash</td>\n",
       "      <td>Male</td>\n",
       "      <td>Not Reported</td>\n",
       "      <td>35-44</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>BAWA</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>unintentional</td>\n",
       "      <td>motor vehicle crash</td>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NACA</td>\n",
       "      <td>National Capital Parks Combined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2008-05-23</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>Motor Vehicle Crash</td>\n",
       "      <td>Male</td>\n",
       "      <td>Driving</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BAWA</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>unintentional</td>\n",
       "      <td>motor vehicle crash</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NACA</td>\n",
       "      <td>National Capital Parks Combined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2008-05-31</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>Motor Vehicle Crash</td>\n",
       "      <td>Female</td>\n",
       "      <td>Driving</td>\n",
       "      <td>25-34</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.5</td>\n",
       "      <td>BAWA</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>unintentional</td>\n",
       "      <td>motor vehicle crash</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NACA</td>\n",
       "      <td>National Capital Parks Combined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2009-02-10</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>Motor Vehicle Crash</td>\n",
       "      <td>Male</td>\n",
       "      <td>Walking</td>\n",
       "      <td>35-44</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>BAWA</td>\n",
       "      <td>Baltimore-Washington Parkway</td>\n",
       "      <td>unintentional</td>\n",
       "      <td>motor vehicle crash</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NACA</td>\n",
       "      <td>National Capital Parks Combined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                      parkName           causeGroup  \\\n",
       "138 2007-12-08  Baltimore-Washington Parkway  Motor Vehicle Crash   \n",
       "142 2007-12-29  Baltimore-Washington Parkway  Motor Vehicle Crash   \n",
       "181 2008-05-23  Baltimore-Washington Parkway  Motor Vehicle Crash   \n",
       "186 2008-05-31  Baltimore-Washington Parkway  Motor Vehicle Crash   \n",
       "296 2009-02-10  Baltimore-Washington Parkway  Motor Vehicle Crash   \n",
       "\n",
       "              sex      activity ageRange  ageMin  ageMax  ageMid parkCode  \\\n",
       "138  Not Reported       Driving  Unknown     NaN     NaN     NaN     BAWA   \n",
       "142          Male  Not Reported    35-44    35.0    44.0    39.5     BAWA   \n",
       "181          Male       Driving  Unknown     NaN     NaN     NaN     BAWA   \n",
       "186        Female       Driving    25-34    25.0    34.0    29.5     BAWA   \n",
       "296          Male       Walking    35-44    35.0    44.0    39.5     BAWA   \n",
       "\n",
       "                     officialName         intent                cause  Month  \\\n",
       "138  Baltimore-Washington Parkway  unintentional  motor vehicle crash     12   \n",
       "142  Baltimore-Washington Parkway  unintentional  motor vehicle crash     12   \n",
       "181  Baltimore-Washington Parkway  unintentional  motor vehicle crash      5   \n",
       "186  Baltimore-Washington Parkway  unintentional  motor vehicle crash      5   \n",
       "296  Baltimore-Washington Parkway  unintentional  motor vehicle crash      2   \n",
       "\n",
       "     Year  NonRecreationVisitors  RecreationVisitors UnitCode  \\\n",
       "138  2007                    NaN                 NaN     NACA   \n",
       "142  2007                    NaN                 NaN     NACA   \n",
       "181  2008                    NaN                 NaN     NACA   \n",
       "186  2008                    NaN                 NaN     NACA   \n",
       "296  2009                    NaN                 NaN     NACA   \n",
       "\n",
       "                            UnitName  \n",
       "138  National Capital Parks Combined  \n",
       "142  National Capital Parks Combined  \n",
       "181  National Capital Parks Combined  \n",
       "186  National Capital Parks Combined  \n",
       "296  National Capital Parks Combined  "
      ]
     },
     "execution_count": 1774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_visits.loc[df_with_visits[\"parkCode\"] == \"BAWA\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1777,
   "id": "c4f2223a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>12</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4530</th>\n",
       "      <td>9</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4565</th>\n",
       "      <td>10</td>\n",
       "      <td>2023</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4599</th>\n",
       "      <td>2</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>3</td>\n",
       "      <td>2024</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Month  Year  RecreationVisitors\n",
       "138      12  2007                 NaN\n",
       "142      12  2007                 NaN\n",
       "181       5  2008                 NaN\n",
       "186       5  2008                 NaN\n",
       "296       2  2009                 NaN\n",
       "...     ...   ...                 ...\n",
       "4530      9  2023                 NaN\n",
       "4551     10  2023                 NaN\n",
       "4565     10  2023                 NaN\n",
       "4599      2  2024                 NaN\n",
       "4628      3  2024                 NaN\n",
       "\n",
       "[83 rows x 3 columns]"
      ]
     },
     "execution_count": 1777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bawa_rows = df_with_visits[df_with_visits[\"parkCode\"] == \"BAWA\"]\n",
    "\n",
    "bawa_rows[[\"Month\", \"Year\", \"RecreationVisitors\"]].sort_values([\"Year\", \"Month\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1780,
   "id": "90eba0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total BAWA rows: 83\n",
      "Rows with RecreationVisitors data: 0\n",
      "Rows missing RecreationVisitors data: 83\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total BAWA rows: {total_bawa}\")\n",
    "print(f\"Rows with RecreationVisitors data: {count_with_data}\")\n",
    "print(f\"Rows missing RecreationVisitors data: {total_bawa - count_with_data}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1786,
   "id": "83bf73d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total acad rows: 210\n",
      "Rows with RecreationVisitors data: 210\n",
      "Rows missing RecreationVisitors data: 0\n"
     ]
    }
   ],
   "source": [
    "# Filter for UnitCode ACAD\n",
    "acad_rows = all_visits_df[all_visits_df[\"UnitCode\"].astype(str).str.upper().eq(\"ACAD\")]\n",
    "\n",
    "# Count rows that have RecreationVisitors data (non-null)\n",
    "yesacad = acad_rows[\"RecreationVisitors\"].notna().sum()\n",
    "\n",
    "# Count rows that are missing RecreationVisitors data (null)\n",
    "noacad = acad_rows[\"RecreationVisitors\"].isna().sum()\n",
    "\n",
    "# Total rows for ACAD\n",
    "total = len(acad_rows)\n",
    "\n",
    "print(f\"Total acad rows: {total}\")\n",
    "print(f\"Rows with RecreationVisitors data: {yesacad}\")\n",
    "print(f\"Rows missing RecreationVisitors data: {noacad}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1787,
   "id": "b2b0fbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No RecreationVisitors values are shared between ACAD and SACR.\n"
     ]
    }
   ],
   "source": [
    "# Filter for ACAD and SACR rows\n",
    "acad_sacr = all_visits_df[all_visits_df[\"UnitCode\"].isin([\"ACAD\", \"SACR\"])]\n",
    "\n",
    "# Find which RecreationVisitors values appear in both parks\n",
    "shared_values = (\n",
    "    acad_sacr.groupby([\"RecreationVisitors\"])[\"UnitCode\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"unit_count\")\n",
    "    .query(\"unit_count > 1\")\n",
    ")\n",
    "\n",
    "# Show which values those are\n",
    "if shared_values.empty:\n",
    "    print(\"No RecreationVisitors values are shared between ACAD and SACR.\")\n",
    "else:\n",
    "    print(\"RecreationVisitors values shared between ACAD and SACR:\")\n",
    "    display(shared_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1784,
   "id": "9ae3c5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate RecreationVisitors values found:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>SACR</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UnitCode  RecreationVisitors  count\n",
       "210     SACR                   0     65"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter for ACAD and SACR rows\n",
    "acad_sacr = all_visits_df[all_visits_df[\"UnitCode\"].isin([\"ACAD\", \"SACR\"])]\n",
    "\n",
    "# Group by UnitCode and RecreationVisitors to find duplicates\n",
    "duplicates = (\n",
    "    acad_sacr.groupby([\"UnitCode\", \"RecreationVisitors\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    "    .query(\"count > 1\")\n",
    ")\n",
    "\n",
    "# Display results\n",
    "if duplicates.empty:\n",
    "    print(\"No duplicate RecreationVisitors values found for ACAD or SACR.\")\n",
    "else:\n",
    "    print(\"Duplicate RecreationVisitors values found:\")\n",
    "    display(duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1785,
   "id": "c0666bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63112</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63113</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63114</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63115</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63122</th>\n",
       "      <td>2013</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63234</th>\n",
       "      <td>2023</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63243</th>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63244</th>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63245</th>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63246</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Month  NonRecreationVisitors\n",
       "63112  2013      1                      0\n",
       "63113  2013      2                      0\n",
       "63114  2013      3                      0\n",
       "63115  2013      4                      0\n",
       "63122  2013     11                      0\n",
       "...     ...    ...                    ...\n",
       "63234  2023      3                      0\n",
       "63243  2023     12                      0\n",
       "63244  2024      1                      0\n",
       "63245  2024      2                      0\n",
       "63246  2024      3                      0\n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 1785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_visits_df.loc[\n",
    "    all_visits_df[\"UnitCode\"].eq(\"SACR\") & all_visits_df[\"RecreationVisitors\"].eq(0),\n",
    "    [\"Year\", \"Month\", \"NonRecreationVisitors\"]\n",
    "].sort_values([\"Year\", \"Month\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1792,
   "id": "660a93f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63112</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63113</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63114</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63115</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63116</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63245</th>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63246</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63247</th>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63248</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>1174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63249</th>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>1854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year  Month  RecreationVisitors\n",
       "63112  2013      1                   0\n",
       "63113  2013      2                   0\n",
       "63114  2013      3                   0\n",
       "63115  2013      4                   0\n",
       "63116  2013      5                1177\n",
       "...     ...    ...                 ...\n",
       "63245  2024      2                   0\n",
       "63246  2024      3                   0\n",
       "63247  2024      4                 682\n",
       "63248  2024      5                1174\n",
       "63249  2024      6                1854\n",
       "\n",
       "[138 rows x 3 columns]"
      ]
     },
     "execution_count": 1792,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_visits_df.loc[\n",
    "    all_visits_df[\"UnitCode\"].eq(\"SACR\"),\n",
    "    [\"Year\", \"Month\", \"RecreationVisitors\"]\n",
    "].sort_values([\"Year\", \"Month\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1791,
   "id": "44233d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>12415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>11068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2007</td>\n",
       "      <td>3</td>\n",
       "      <td>19220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>2007</td>\n",
       "      <td>4</td>\n",
       "      <td>61775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>2007</td>\n",
       "      <td>5</td>\n",
       "      <td>132152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>14071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>25696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>95165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>320885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>599015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Month  RecreationVisitors\n",
       "210  2007      1               12415\n",
       "211  2007      2               11068\n",
       "212  2007      3               19220\n",
       "213  2007      4               61775\n",
       "214  2007      5              132152\n",
       "..    ...    ...                 ...\n",
       "415  2024      2               14071\n",
       "416  2024      3               25696\n",
       "417  2024      4               95165\n",
       "418  2024      5              320885\n",
       "419  2024      6              599015\n",
       "\n",
       "[210 rows x 3 columns]"
      ]
     },
     "execution_count": 1791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_visits_df.loc[\n",
    "    all_visits_df[\"UnitCode\"].eq(\"ACAD\"),\n",
    "    [\"Year\", \"Month\", \"RecreationVisitors\"]\n",
    "].sort_values([\"Year\", \"Month\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1230275",
   "metadata": {},
   "source": [
    "I know that SACR is part of ACAD, but I also know that SACR is closed in winter months. When I look at overlapping results between the two, it doesn't seem like ACAD would be a fair or accurate representation of the visitors at the SACR site because there are many winter visitors in ACAD while SACR is closed. I will not fill any rows with data from ACAD, despita the organizational affiliation, because it would be more damaging to my analysis to have inaccurate data than incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1810,
   "id": "b25538b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Filter for SACR rows\n",
    "sacr_rows = df_with_visits[df_with_visits[\"UnitCode\"].astype(str).str.upper().eq(\"SACR\")]\n",
    "\n",
    "# Count missing values in RecreationVisitors and NonRecreationVisitors\n",
    "missing_recreation = sacr_rows[\"RecreationVisitors\"].isna().sum()\n",
    "missing_nonrecreation = sacr_rows[\"NonRecreationVisitors\"].isna().sum()\n",
    "\n",
    "# Total number of SACR rows for context\n",
    "total_sacr = len(sacr_rows)\n",
    "\n",
    "print(f\"{total_sacr}\")\n",
    "print(f\"{missing_recreation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1794,
   "id": "a0b7da95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows missing RecreationVisitors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Month  RecreationVisitors  NonRecreationVisitors\n",
       "879  2012      8                 NaN                    NaN\n",
       "910  2012     10                 NaN                    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rows missing NonRecreationVisitors:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Month  RecreationVisitors  NonRecreationVisitors\n",
       "879  2012      8                 NaN                    NaN\n",
       "910  2012     10                 NaN                    NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show rows missing RecreationVisitors\n",
    "missing_recreation = sacr_rows[sacr_rows[\"RecreationVisitors\"].isna()][[\"Year\", \"Month\", \"RecreationVisitors\", \"NonRecreationVisitors\"]]\n",
    "\n",
    "# Show rows missing NonRecreationVisitors\n",
    "missing_nonrecreation = sacr_rows[sacr_rows[\"NonRecreationVisitors\"].isna()][[\"Year\", \"Month\", \"RecreationVisitors\", \"NonRecreationVisitors\"]]\n",
    "\n",
    "print(\"Rows missing RecreationVisitors:\")\n",
    "display(missing_recreation.sort_values([\"Year\", \"Month\"]))\n",
    "\n",
    "print(\"\\nRows missing NonRecreationVisitors:\")\n",
    "display(missing_nonrecreation.sort_values([\"Year\", \"Month\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794be4b",
   "metadata": {},
   "source": [
    "I have several years of complete data for 2013 on, so I feel comfortable trying to use those years of data to approximate the missing information for those two rows. I believe I will likely be able to get a close approximation and the effect of using a number that may be slightly inaccurate will minimal on the overall analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1796,
   "id": "c163e333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>892.416667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>965.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1046.416667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1154.750000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>989.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RecreationVisitors  NonRecreationVisitors\n",
       "Year                                           \n",
       "2013          892.416667                    0.0\n",
       "2014          965.666667                    0.0\n",
       "2015         1046.416667                    0.0\n",
       "2016         1154.750000                    0.0\n",
       "2017          989.333333                    0.0"
      ]
     },
     "execution_count": 1796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Calculate the yearly averages\n",
    "yearly_avg = (\n",
    "    sacr_train.groupby(\"Year\")[[\"RecreationVisitors\", \"NonRecreationVisitors\"]]\n",
    "    .mean()\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "yearly_avg.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd7d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>1.082080</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1.083621</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1.103528</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>0.856751</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1.010866</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>0.967669</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>0.595367</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>1.489586</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>1.178658</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RecreationVisitors  NonRecreationVisitors\n",
       "Year                                           \n",
       "2013                 NaN                    NaN\n",
       "2014            1.082080                    NaN\n",
       "2015            1.083621                    NaN\n",
       "2016            1.103528                    NaN\n",
       "2017            0.856751                    NaN\n",
       "2018            1.010866                    NaN\n",
       "2019            0.967669                    NaN\n",
       "2020            0.595367                    NaN\n",
       "2021            1.489586                    NaN\n",
       "2022            1.178658                    NaN"
      ]
     },
     "execution_count": 1799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yoy = yearly_avg.pct_change().add(1)\n",
    "\n",
    "yoy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca575e",
   "metadata": {},
   "source": [
    "I believe that the earlier year in this series of data is more fairly representative of the change that likely occured in my missing years because those value points are reasonably consistent in representing 8-10% YOY growth. I will use only those 3 data points to estimate my missing values to avoid outliers toward the end of the dataset (such as 2020/pandemic year) skewing what appears to have been a stable period of growth. I also can see that NonRecreationVisitors is 0 in all avaialable fields, so I'll ultimately fill 0 for the missing fields, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1801,
   "id": "b92cc7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0897431309964691)"
      ]
     },
     "execution_count": 1801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter for the first 3 non-null points (2014–2016)\n",
    "stable_years = yoy.loc[yoy.index.isin([2014, 2015, 2016])]\n",
    "\n",
    "#Calculate average growth for those years only\n",
    "avg_growth = stable_years[\"RecreationVisitors\"].mean(skipna=True)\n",
    "\n",
    "avg_growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a04e20e",
   "metadata": {},
   "source": [
    "Now I'll calculate the monthly averages from the stable rows only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1805,
   "id": "61b95bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecreationVisitors_month_avg</th>\n",
       "      <th>NonRecreationVisitors_month_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1086.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1704.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2887.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2974.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2272.75</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1252.50</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RecreationVisitors_month_avg  NonRecreationVisitors_month_avg\n",
       "Month                                                               \n",
       "1                              0.00                              0.0\n",
       "2                              0.00                              0.0\n",
       "3                              0.00                              0.0\n",
       "4                              0.00                              0.0\n",
       "5                           1086.00                              0.0\n",
       "6                           1704.25                              0.0\n",
       "7                           2887.75                              0.0\n",
       "8                           2974.50                              0.0\n",
       "9                           2272.75                              0.0\n",
       "10                          1252.50                              0.0\n",
       "11                             0.00                              0.0\n",
       "12                             0.00                              0.0"
      ]
     },
     "execution_count": 1805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter SACR rows from all_visits_df\n",
    "sacr_visits = all_visits_df[all_visits_df[\"UnitCode\"] == \"SACR\"].copy()\n",
    "\n",
    "# Combine year and month fields to make numeric value that can be compared in series order\n",
    "sacr_visits[\"Year\"] = sacr_visits[\"Year\"].astype(int)\n",
    "sacr_visits[\"Month\"] = sacr_visits[\"Month\"].astype(int)\n",
    "sacr_visits[\"year_month\"] = sacr_visits[\"Year\"] * 100 + sacr_visits[\"Month\"]\n",
    "\n",
    "# Use only stable early years (2013–2016) for training\n",
    "early = sacr_visits[sacr_visits[\"Year\"].between(2013, 2016)].copy()\n",
    "\n",
    "# Add column with calculated monthly averages\n",
    "monthly_avg = (\n",
    "    early.groupby(\"Month\")[[\"RecreationVisitors\", \"NonRecreationVisitors\"]]\n",
    "    .mean()\n",
    "    .rename(columns={\n",
    "        \"RecreationVisitors\": \"RecreationVisitors_month_avg\",\n",
    "        \"NonRecreationVisitors\": \"NonRecreationVisitors_month_avg\"\n",
    "    })\n",
    ")\n",
    "monthly_avg.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1807,
   "id": "a882ba22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UnitCode</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>RecreationVisitors</th>\n",
       "      <th>NonRecreationVisitors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>SACR</td>\n",
       "      <td>2012</td>\n",
       "      <td>8</td>\n",
       "      <td>2977.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>SACR</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    UnitCode  Year  Month  RecreationVisitors  NonRecreationVisitors\n",
       "879     SACR  2012      8              2977.0                    0.0\n",
       "910     SACR  2012     10              1254.0                    0.0"
      ]
     },
     "execution_count": 1807,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate 2012 August & October values using monthly averages and early-period growth\n",
    "target_months = [8, 10]\n",
    "estimates_2012 = {}\n",
    "for m in target_months:\n",
    "    rec_val = monthly_avg.loc[m, \"RecreationVisitors_month_avg\"] / avg_growth_rec\n",
    "    # Round to whole people\n",
    "    rec_val = int(round(rec_val))\n",
    "\n",
    "    estimates_2012[m] = {\n",
    "        \"RecreationVisitors\": rec_val,\n",
    "        \"NonRecreationVisitors\": 0\n",
    "    }\n",
    "\n",
    "# Fill nulls in df_with_visits\n",
    "for m in target_months:\n",
    "    mask = (\n",
    "        (df_with_visits[\"UnitCode\"] == \"SACR\") &\n",
    "        (df_with_visits[\"Year\"] == 2012) &\n",
    "        (df_with_visits[\"Month\"] == m)\n",
    "    )\n",
    "\n",
    "    if m in estimates_2012:\n",
    "        df_with_visits.loc[\n",
    "            mask & df_with_visits[\"RecreationVisitors\"].isna(),\n",
    "            \"RecreationVisitors\"\n",
    "        ] = estimates_2012[m][\"RecreationVisitors\"]\n",
    "\n",
    "        df_with_visits.loc[\n",
    "            mask & df_with_visits[\"NonRecreationVisitors\"].isna(),\n",
    "            \"NonRecreationVisitors\"\n",
    "        ] = 0\n",
    "\n",
    "# Inspect results\n",
    "df_with_visits.loc[\n",
    "    (df_with_visits[\"UnitCode\"] == \"SACR\") &\n",
    "    (df_with_visits[\"Year\"] == 2012) &\n",
    "    (df_with_visits[\"Month\"].isin(target_months)),\n",
    "    [\"UnitCode\", \"Year\", \"Month\", \"RecreationVisitors\", \"NonRecreationVisitors\"]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a440f6",
   "metadata": {},
   "source": [
    "Sanity check: I'll rerun this to see if there are still any missing rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1811,
   "id": "75b1453f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Filter for SACR rows\n",
    "sacr_rows = df_with_visits[df_with_visits[\"UnitCode\"].astype(str).str.upper().eq(\"SACR\")]\n",
    "\n",
    "# Count missing values in RecreationVisitors and NonRecreationVisitors\n",
    "missing_recreation = sacr_rows[\"RecreationVisitors\"].isna().sum()\n",
    "missing_nonrecreation = sacr_rows[\"NonRecreationVisitors\"].isna().sum()\n",
    "\n",
    "# Total number of SACR rows for context\n",
    "total_sacr = len(sacr_rows)\n",
    "\n",
    "print(f\"{total_sacr}\")\n",
    "print(f\"{missing_recreation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
